{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC_Block(nn.Module) : \n",
    "    def __init__(self, input_dim, output_dim) : \n",
    "        super(FC_Block, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.bn = nn.BatchNorm1d(output_dim)\n",
    "        self.dr = nn.Dropout()\n",
    "\n",
    "    def forward(self, x) : \n",
    "        out = self.linear(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dr(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Classifier(nn.Module) : \n",
    "    def __init__(self, fc_block, num_classes = 10) : \n",
    "        super(MLP_Classifier, self).__init__()\n",
    "        self.fc1 = fc_block(784, 256)\n",
    "        self.fc2 = fc_block(256,64)\n",
    "        self.fc3 = fc_block(64,16)\n",
    "        self.linear = nn.Linear(16, num_classes)\n",
    "        self.output = nn.Softmax()\n",
    "    \n",
    "    def forward(self, x) : \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.output(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP_Classifier(FC_Block, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = dset.MNIST(\"./\", train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
    "mnist_test = dset.MNIST(\"./\", train=False, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
    "mnist_train, mnist_val = torch.utils.data.random_split(mnist_train, [48000, 12000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {}\n",
    "batch_size = 480\n",
    "dataloaders['train'] = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "dataloaders['val'] = DataLoader(mnist_val, batch_size=batch_size, shuffle=False)\n",
    "dataloaders['test'] = DataLoader(mnist_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "mlp = MLP_Classifier(FC_Block, 10).to(device)\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.1, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Current Epoch :  0  ===\n",
      "train Loss: 1.9259496927261353 / Acc : 0.5338333249092102\n",
      "val Loss: 1.7370600700378418 / Acc : 0.7228333353996277\n",
      "=== Current Epoch :  1  ===\n",
      "train Loss: 1.8432836532592773 / Acc : 0.6219375133514404\n",
      "val Loss: 1.7151570320129395 / Acc : 0.746916651725769\n",
      "=== Current Epoch :  2  ===\n",
      "train Loss: 1.8346511125564575 / Acc : 0.6301041841506958\n",
      "val Loss: 1.7111871242523193 / Acc : 0.7534166574478149\n",
      "=== Current Epoch :  3  ===\n",
      "train Loss: 1.8341000080108643 / Acc : 0.629729151725769\n",
      "val Loss: 1.6606887578964233 / Acc : 0.8048333525657654\n",
      "=== Current Epoch :  4  ===\n",
      "train Loss: 1.8236664533615112 / Acc : 0.6413541436195374\n",
      "val Loss: 1.6614594459533691 / Acc : 0.8015833497047424\n",
      "=== Current Epoch :  5  ===\n",
      "train Loss: 1.8299202919006348 / Acc : 0.6355416774749756\n",
      "val Loss: 1.6827470064163208 / Acc : 0.7800832986831665\n",
      "=== Current Epoch :  6  ===\n",
      "train Loss: 1.8324944972991943 / Acc : 0.6333958506584167\n",
      "val Loss: 1.676156759262085 / Acc : 0.7867500185966492\n",
      "=== Current Epoch :  7  ===\n",
      "train Loss: 1.8217051029205322 / Acc : 0.6448749899864197\n",
      "val Loss: 1.649116039276123 / Acc : 0.8136666417121887\n",
      "=== Current Epoch :  8  ===\n",
      "train Loss: 1.8214168548583984 / Acc : 0.6442708373069763\n",
      "val Loss: 1.6653352975845337 / Acc : 0.7985000014305115\n",
      "=== Current Epoch :  9  ===\n",
      "train Loss: 1.7559586763381958 / Acc : 0.7136250138282776\n",
      "val Loss: 1.559108853340149 / Acc : 0.9037500023841858\n",
      "=== Current Epoch :  10  ===\n",
      "train Loss: 1.6985344886779785 / Acc : 0.7741875052452087\n",
      "val Loss: 1.5540939569473267 / Acc : 0.9087499976158142\n",
      "=== Current Epoch :  11  ===\n",
      "train Loss: 1.6836373805999756 / Acc : 0.7881875038146973\n",
      "val Loss: 1.5481181144714355 / Acc : 0.9147499799728394\n",
      "=== Current Epoch :  12  ===\n",
      "train Loss: 1.6820385456085205 / Acc : 0.7890625\n",
      "val Loss: 1.5519447326660156 / Acc : 0.9105833172798157\n",
      "=== Current Epoch :  13  ===\n",
      "train Loss: 1.677340030670166 / Acc : 0.7948333024978638\n",
      "val Loss: 1.546755075454712 / Acc : 0.9160000085830688\n",
      "=== Current Epoch :  14  ===\n",
      "train Loss: 1.6763149499893188 / Acc : 0.7945625185966492\n",
      "val Loss: 1.5479540824890137 / Acc : 0.9144166707992554\n",
      "=== Current Epoch :  15  ===\n",
      "train Loss: 1.6720043420791626 / Acc : 0.7992291450500488\n",
      "val Loss: 1.5416369438171387 / Acc : 0.9209166765213013\n",
      "=== Current Epoch :  16  ===\n",
      "train Loss: 1.6721038818359375 / Acc : 0.7986458539962769\n",
      "val Loss: 1.5400956869125366 / Acc : 0.9226666688919067\n",
      "=== Current Epoch :  17  ===\n",
      "train Loss: 1.6695963144302368 / Acc : 0.8012708425521851\n",
      "val Loss: 1.544853925704956 / Acc : 0.9175000190734863\n",
      "=== Current Epoch :  18  ===\n",
      "train Loss: 1.6644312143325806 / Acc : 0.8065000176429749\n",
      "val Loss: 1.5371801853179932 / Acc : 0.9259166717529297\n",
      "=== Current Epoch :  19  ===\n",
      "train Loss: 1.654208779335022 / Acc : 0.8164374828338623\n",
      "val Loss: 1.530350923538208 / Acc : 0.9324166774749756\n",
      "=== Current Epoch :  20  ===\n",
      "train Loss: 1.645032286643982 / Acc : 0.8261666297912598\n",
      "val Loss: 1.5266895294189453 / Acc : 0.9361666440963745\n",
      "=== Current Epoch :  21  ===\n",
      "train Loss: 1.6390939950942993 / Acc : 0.8325208425521851\n",
      "val Loss: 1.5251753330230713 / Acc : 0.9375\n",
      "=== Current Epoch :  22  ===\n",
      "train Loss: 1.6349114179611206 / Acc : 0.835854172706604\n",
      "val Loss: 1.5235620737075806 / Acc : 0.9385833144187927\n",
      "=== Current Epoch :  23  ===\n",
      "train Loss: 1.63616144657135 / Acc : 0.8355833292007446\n",
      "val Loss: 1.5242161750793457 / Acc : 0.937833309173584\n",
      "=== Current Epoch :  24  ===\n",
      "train Loss: 1.6297602653503418 / Acc : 0.8416875004768372\n",
      "val Loss: 1.5219815969467163 / Acc : 0.940833330154419\n",
      "=== Current Epoch :  25  ===\n",
      "train Loss: 1.6281492710113525 / Acc : 0.843791663646698\n",
      "val Loss: 1.5216342210769653 / Acc : 0.940833330154419\n",
      "=== Current Epoch :  26  ===\n",
      "train Loss: 1.628531813621521 / Acc : 0.8434166312217712\n",
      "val Loss: 1.520513892173767 / Acc : 0.9416666626930237\n",
      "=== Current Epoch :  27  ===\n",
      "train Loss: 1.627315640449524 / Acc : 0.8438958525657654\n",
      "val Loss: 1.5200114250183105 / Acc : 0.9426666498184204\n",
      "=== Current Epoch :  28  ===\n",
      "train Loss: 1.6274282932281494 / Acc : 0.8448749780654907\n",
      "val Loss: 1.5203335285186768 / Acc : 0.9422500133514404\n",
      "=== Current Epoch :  29  ===\n",
      "train Loss: 1.625636100769043 / Acc : 0.8457708358764648\n",
      "val Loss: 1.519490361213684 / Acc : 0.9428333044052124\n",
      "=== Current Epoch :  30  ===\n",
      "train Loss: 1.6234667301177979 / Acc : 0.848354160785675\n",
      "val Loss: 1.5192670822143555 / Acc : 0.9433333277702332\n",
      "=== Current Epoch :  31  ===\n",
      "train Loss: 1.6207550764083862 / Acc : 0.8510000109672546\n",
      "val Loss: 1.5188645124435425 / Acc : 0.9430000185966492\n",
      "=== Current Epoch :  32  ===\n",
      "train Loss: 1.6218373775482178 / Acc : 0.8499583005905151\n",
      "val Loss: 1.5174726247787476 / Acc : 0.9446666836738586\n",
      "=== Current Epoch :  33  ===\n",
      "train Loss: 1.619745135307312 / Acc : 0.851854145526886\n",
      "val Loss: 1.5166736841201782 / Acc : 0.9456666707992554\n",
      "=== Current Epoch :  34  ===\n",
      "train Loss: 1.6217378377914429 / Acc : 0.8494791388511658\n",
      "val Loss: 1.51704740524292 / Acc : 0.9449999928474426\n",
      "=== Current Epoch :  35  ===\n",
      "train Loss: 1.6212828159332275 / Acc : 0.8503333330154419\n",
      "val Loss: 1.5172398090362549 / Acc : 0.9449999928474426\n",
      "=== Current Epoch :  36  ===\n",
      "train Loss: 1.6193903684616089 / Acc : 0.8523125052452087\n",
      "val Loss: 1.515747308731079 / Acc : 0.9466666579246521\n",
      "=== Current Epoch :  37  ===\n",
      "train Loss: 1.6205805540084839 / Acc : 0.8505208492279053\n",
      "val Loss: 1.5159209966659546 / Acc : 0.9459166526794434\n",
      "=== Current Epoch :  38  ===\n",
      "train Loss: 1.6180486679077148 / Acc : 0.8535000085830688\n",
      "val Loss: 1.5162692070007324 / Acc : 0.9461666345596313\n",
      "=== Current Epoch :  39  ===\n",
      "train Loss: 1.6188737154006958 / Acc : 0.8522499799728394\n",
      "val Loss: 1.5159963369369507 / Acc : 0.9466666579246521\n",
      "=== Current Epoch :  40  ===\n",
      "train Loss: 1.6186373233795166 / Acc : 0.8527083396911621\n",
      "val Loss: 1.5147866010665894 / Acc : 0.9478332996368408\n",
      "=== Current Epoch :  41  ===\n",
      "train Loss: 1.6187646389007568 / Acc : 0.8531875014305115\n",
      "val Loss: 1.5154588222503662 / Acc : 0.9465833306312561\n",
      "=== Current Epoch :  42  ===\n",
      "train Loss: 1.6163967847824097 / Acc : 0.854770839214325\n",
      "val Loss: 1.5147016048431396 / Acc : 0.9477499723434448\n",
      "=== Current Epoch :  43  ===\n",
      "train Loss: 1.617053508758545 / Acc : 0.8540832996368408\n",
      "val Loss: 1.5139923095703125 / Acc : 0.9484166502952576\n",
      "=== Current Epoch :  44  ===\n",
      "train Loss: 1.6169413328170776 / Acc : 0.8551666736602783\n",
      "val Loss: 1.514574646949768 / Acc : 0.9483333230018616\n",
      "=== Current Epoch :  45  ===\n",
      "train Loss: 1.6155198812484741 / Acc : 0.8563125133514404\n",
      "val Loss: 1.5136271715164185 / Acc : 0.9492499828338623\n",
      "=== Current Epoch :  46  ===\n",
      "train Loss: 1.6167407035827637 / Acc : 0.8543124794960022\n",
      "val Loss: 1.512602686882019 / Acc : 0.9493333101272583\n",
      "=== Current Epoch :  47  ===\n",
      "train Loss: 1.6155447959899902 / Acc : 0.8563125133514404\n",
      "val Loss: 1.5123445987701416 / Acc : 0.950333297252655\n",
      "=== Current Epoch :  48  ===\n",
      "train Loss: 1.6118229627609253 / Acc : 0.8604999780654907\n",
      "val Loss: 1.512471079826355 / Acc : 0.9497500061988831\n",
      "=== Current Epoch :  49  ===\n",
      "train Loss: 1.6126210689544678 / Acc : 0.8588125109672546\n",
      "val Loss: 1.5129154920578003 / Acc : 0.9493333101272583\n",
      "Training complete in 3m 54s\n",
      "Best val Loss: 1.512345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase = 'train'\n",
    "train_loss_history = []\n",
    "valid_loss_history = []\n",
    "best_val_loss = 10000\n",
    "since = time.time()\n",
    "early_stop_epoch = 0\n",
    "\n",
    "for epoch in range(50) : \n",
    "    print('=== Current Epoch : ', epoch, ' ===')\n",
    "\n",
    "    for phase in ['train','val'] : \n",
    "        if phase == 'train' : \n",
    "            mlp.train()\n",
    "        else : \n",
    "            mlp.eval()\n",
    "\n",
    "        epoch_loss = 0\n",
    "        running_acc = 0\n",
    "        total = 0\n",
    "\n",
    "        for batch_idx, (x,y) in enumerate(dataloaders[phase]) : \n",
    "            x,y = x.view(-1, 28*28).to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = mlp(x)\n",
    "            running_acc += sum(out.argmax(1) == y)\n",
    "            total += x.size(0)\n",
    "            loss = criterion(out, y)\n",
    "            epoch_loss += loss / 480\n",
    "\n",
    "            if phase == 'train' : \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "        \n",
    "        epoch_acc = running_acc / total\n",
    "        print(f'{phase} Loss: {epoch_loss} / Acc : {epoch_acc}')\n",
    "\n",
    "        if phase == 'train' : \n",
    "            train_loss_history.append([epoch_loss, epoch_acc])\n",
    "        elif phase == 'val' : \n",
    "            valid_loss_history.append([epoch_loss, epoch_acc])\n",
    "\n",
    "        if (phase == 'val') and (epoch_loss  < best_val_loss) : \n",
    "            best_val_loss = epoch_loss\n",
    "            best_model_wts = copy.deepcopy(mlp.state_dict())\n",
    "            early_stop_epoch = 0\n",
    "        elif phase == 'val' : \n",
    "            early_stop_epoch += 1\n",
    "            if early_stop_epoch > 10 :\n",
    "                break;\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "print('Best val Loss: {:4f}'.format(best_val_loss))\n",
    "\n",
    "# load best model weights\n",
    "mlp.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9541\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    mlp.eval()    # set the model to evaluation mode (dropout=False)\n",
    "    test_acc = 0\n",
    "    test_size = 0\n",
    "    for x,y in dataloaders['test'] : \n",
    "        x,y = x.view(-1, 28*28).to(device), y.to(device)\n",
    "\n",
    "        prediction = mlp(x)\n",
    "        test_acc += sum(prediction.argmax(1) == y)\n",
    "        test_size += x.size(0)\n",
    "    print('Test Accuracy:', test_acc.item() / test_size)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
