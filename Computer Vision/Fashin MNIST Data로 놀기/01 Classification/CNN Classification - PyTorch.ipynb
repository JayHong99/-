{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Foo](https://miro.medium.com/max/857/1*AqqArOvacibWqeulyP_-8Q.png)](http://google.com.au/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 일단 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionCNN(nn.Module) : \n",
    "    def __init__(self) : \n",
    "        super(FashionCNN,self).__init__()\n",
    "\n",
    "        self.cnn_block1 = nn.Sequential(\n",
    "            # 28x28x1 -> 28x28x32 -> 14x14x32\n",
    "            nn.Conv2d(1, 32, 3, padding = 1), nn.LeakyReLU(0.2), nn.BatchNorm2d(32), nn.Dropout(0.1),\n",
    "            nn.Conv2d(32, 32, 3, padding = 1), nn.LeakyReLU(0.2), nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2,2))\n",
    "        \n",
    "        self.cnn_block2 = nn.Sequential(\n",
    "            # 14x14x32 -> 14x14x64 -> 7x7x64\n",
    "            nn.Conv2d(32, 64, 3, padding = 1), nn.LeakyReLU(0.2),nn.BatchNorm2d(64), nn.Dropout(0.1),\n",
    "            nn.Conv2d(64,64,3, padding=1), nn.LeakyReLU(0.2),nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2,2)\n",
    "            )\n",
    "\n",
    "        self.cnn_block3 = nn.Sequential(\n",
    "            # 7x7x64 -> 7x7x128 -> 1x1x128\n",
    "            nn.Conv2d(64, 128, 3, padding = 1), nn.LeakyReLU(0.2),nn.BatchNorm2d(128), nn.Dropout(0.1),\n",
    "            nn.Conv2d(128, 128, 3, padding = 1), nn.LeakyReLU(0.2),nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(7)\n",
    "            )\n",
    "\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            # 128 ->  10\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    \n",
    "    def forward(self, x) :\n",
    "        batch_size = x.size(0)\n",
    "        x = self.cnn_block1(x)\n",
    "        x = self.cnn_block2(x)\n",
    "        x = self.cnn_block3(x)\n",
    " \n",
    "        x = x.view(batch_size,-1)\n",
    "        \n",
    "        x = self.fc_layer(x)\n",
    "        return F.softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "fmnist_train = dset.FashionMNIST(\"./\", train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
    "fmnist_test = dset.FashionMNIST(\"./\", train=False, transform=transforms.ToTensor(), target_transform=None, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "n_split = 5\n",
    "skf = StratifiedKFold(n_splits = n_split, shuffle = True)\n",
    "\n",
    "for train_idx, valid_idx in skf.split(np.arange(fmnist_train.__len__()), fmnist_train.targets) : \n",
    "    break;\n",
    "\n",
    "def return_dataloader(train_idx, valid_idx) : \n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "    valid_subsampler = torch.utils.data.SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    train_data = DataLoader(dataset=fmnist_train, batch_size = batch_size, sampler = train_subsampler)\n",
    "    valid_data = DataLoader(dataset=fmnist_train, batch_size = batch_size, sampler = valid_subsampler)\n",
    "    \n",
    "\n",
    "    dataloaders = {}\n",
    "    dataloaders['train'] = train_data\n",
    "    dataloaders['valid'] = valid_data\n",
    "\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, optimizer, criterion, num_epoch, early_stop, model_path) : \n",
    "    import time\n",
    "\n",
    "    start_time = time.time()\n",
    "    early_stop_epoch = 0\n",
    "    best_val_loss = np.float('inf')\n",
    "\n",
    "    for epoch in range(num_epoch) : \n",
    "        for phase in ['train','valid'] : \n",
    "            if phase == 'train' : \n",
    "                model.train()\n",
    "            elif phase == 'valid' : \n",
    "                model.eval()\n",
    "            \n",
    "            running_loss = 0\n",
    "            running_corr = 0\n",
    "            total = 0 \n",
    "\n",
    "\n",
    "            for x, y in dataloader[phase] : \n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                total += x.size(0)\n",
    "\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train') : \n",
    "                    output = model(x)\n",
    "                    loss = criterion(output, y)\n",
    "                    \n",
    "                    if phase == 'train' : \n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                running_corr += (output.argmax(1)==y).sum().item()\n",
    "            \n",
    "            epoch_loss = running_loss / total\n",
    "            epoch_acc = running_corr / total\n",
    "\n",
    "            if phase == 'valid' and epoch_loss < best_val_loss : \n",
    "                print(f'On Epoch {epoch}, Best Model Saved with Valid Loss {round(epoch_loss, 6)} and Acc {round(epoch_acc, 4)*100}%')\n",
    "                \n",
    "                best_val_loss = epoch_loss\n",
    "                best_acc = epoch_acc\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                early_stop_epoch = 0\n",
    "        \n",
    "            elif phase == 'valid' : \n",
    "                early_stop_epoch += 1\n",
    "\n",
    "        if early_stop_epoch >= early_stop : \n",
    "            \"Early Stop Occured on epoch\" + str(epoch)\n",
    "            break;\n",
    "    time_elapsed = time.time() - start_time\n",
    "    print(f'Training Complete in {time_elapsed//60}min {time_elapsed%60}sec')\n",
    "    print(f'Best Validation Loss : {round(best_val_loss, 6)} with Accuracy {round(best_acc,4)*100}%')\n",
    "\n",
    "\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Epoch 0, Best Model Saved with Valid Loss 0.003605 and Acc 65.95%\n",
      "On Epoch 1, Best Model Saved with Valid Loss 0.00356 and Acc 67.71000000000001%\n",
      "On Epoch 2, Best Model Saved with Valid Loss 0.00351 and Acc 70.27%\n",
      "On Epoch 3, Best Model Saved with Valid Loss 0.003326 and Acc 79.74%\n",
      "On Epoch 4, Best Model Saved with Valid Loss 0.003133 and Acc 89.68%\n",
      "On Epoch 5, Best Model Saved with Valid Loss 0.003132 and Acc 89.55%\n",
      "On Epoch 6, Best Model Saved with Valid Loss 0.003132 and Acc 89.57000000000001%\n",
      "On Epoch 7, Best Model Saved with Valid Loss 0.003105 and Acc 90.88000000000001%\n",
      "On Epoch 8, Best Model Saved with Valid Loss 0.003104 and Acc 90.93%\n",
      "On Epoch 10, Best Model Saved with Valid Loss 0.003091 and Acc 91.49000000000001%\n",
      "On Epoch 12, Best Model Saved with Valid Loss 0.003088 and Acc 91.72%\n",
      "On Epoch 15, Best Model Saved with Valid Loss 0.003087 and Acc 91.7%\n",
      "On Epoch 20, Best Model Saved with Valid Loss 0.003081 and Acc 92.10000000000001%\n",
      "On Epoch 21, Best Model Saved with Valid Loss 0.00308 and Acc 92.01%\n",
      "Training Complete in 11.0min 40.78444838523865sec\n",
      "Best Validation Loss : 0.00308 with Accuracy 92.01%\n"
     ]
    }
   ],
   "source": [
    "fcnn = FashionCNN().to(device)\n",
    "dataloader = return_dataloader(train_idx, valid_idx)\n",
    "optimizer = optim.Adam(fcnn.parameters(), lr = 0.005)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "trained_fcnn = train_model(fcnn, dataloader, optimizer, loss_fn, num_epoch = 100, early_stop = 5, model_path =  'FCNN.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloder = DataLoader(dataset = fmnist_test, batch_size  = batch_size , shuffle = False)\n",
    "class_correct = [0 for x in fmnist_test.classes]\n",
    "total_correct = [0 for x in fmnist_test.classes]\n",
    "with torch.no_grad() : \n",
    "    for images, labels in test_dataloder : \n",
    "        images = images.to(device)\n",
    "        prediction_soft = trained_fcnn(images)\n",
    "        prediction_hard = prediction_soft.argmax(1)\n",
    "\n",
    "        correction = (prediction_hard.cpu() == labels).squeeze()\n",
    "\n",
    "        for label,corr in zip(labels, correction) : \n",
    "            total_correct[label] += 1\n",
    "            if corr : \n",
    "                class_correct[label] += 1\n",
    "acc_per_class = [cl/to for cl, to in zip(class_correct, total_correct)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 옷 종류에 대해서 혼동하는 양상을 보임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of T-shirt/top : 86.9%\n",
      "Accuracy of Trouser : 98.1%\n",
      "Accuracy of Pullover : 84.4%\n",
      "Accuracy of Dress : 92.0%\n",
      "Accuracy of Coat : 89.8%\n",
      "Accuracy of Sandal : 98.0%\n",
      "Accuracy of Shirt : 75.4%\n",
      "Accuracy of Sneaker : 98.9%\n",
      "Accuracy of Bag : 99.2%\n",
      "Accuracy of Ankle boot : 94.9%\n",
      "\n",
      "Total Accuracy : 0.9176%\n"
     ]
    }
   ],
   "source": [
    "for cls, acc in zip(fmnist_test.classes, acc_per_class) : \n",
    "    print(f'Accuracy of {cls} : {round(acc*100,2)}%')\n",
    "print('')\n",
    "print(f'Total Accuracy : {round(sum(class_correct) / sum(total_correct), 4)}%')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
