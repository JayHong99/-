{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "fmnist_train = dset.FashionMNIST(\"./\", train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
    "fmnist_test = dset.FashionMNIST(\"./\", train=False, transform=transforms.ToTensor(), target_transform=None, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "n_split = 5\n",
    "skf = StratifiedKFold(n_splits = n_split, shuffle = True)\n",
    "\n",
    "for train_idx, valid_idx in skf.split(np.arange(fmnist_train.__len__()), fmnist_train.targets) : \n",
    "    break;\n",
    "\n",
    "def return_dataloader(train_idx, valid_idx) : \n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "    valid_subsampler = torch.utils.data.SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    train_data = DataLoader(dataset=fmnist_train, batch_size = batch_size, sampler = train_subsampler)\n",
    "    valid_data = DataLoader(dataset=fmnist_train, batch_size = batch_size, sampler = valid_subsampler)\n",
    "    \n",
    "\n",
    "    dataloaders = {}\n",
    "    dataloaders['train'] = train_data\n",
    "    dataloaders['valid'] = valid_data\n",
    "\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 모델 구조\n",
    "- Input : 1x28x28 Image\n",
    "- Model : \n",
    "    - 1x28x28 -> conv(3x3) -> bn -> relu -> 16x28x28\n",
    "    - layers2n : 16x28x28 -> 16x28x28 -> 16x28x28\n",
    "    - layers4n : 32x28x28 (Down Sampling) -> 32x28x28 -> 32x28x28\n",
    "    - layers6n : 64x28x28 (Down Sampling) -> 64x28x28 -> 64x28x28\n",
    "    - AvgPool  : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = return_dataloader(train_idx, valid_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Convolution Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module) : \n",
    "    def __init__(self, in_channels, out_channels, stride = 1, down_sample = False) : \n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.stride = stride\n",
    "        self.down_sample = down_sample\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                                stride = stride, padding = 1, bias = False)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, \n",
    "                                stride = 1, padding = 1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def down_sampling(self, x) : \n",
    "        out = F.pad(x, (0,0,0,0,0, self.out_channels - self.in_channels))\n",
    "        out = nn.MaxPool2d(2, stride = self.stride)(out)\n",
    "        return out\n",
    "\n",
    "    def forward(self, x ) : \n",
    "        short_cut = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out) \n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.down_sample : \n",
    "            short_cut = self.down_sampling(x)\n",
    "        \n",
    "        out += short_cut\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module) : \n",
    "    def __init__(self, num_layers, block, num_classes = 10) : \n",
    "        super(ResNet, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels= 1,\n",
    "            out_channels=16,\n",
    "            kernel_size=3,\n",
    "            stride = 1,\n",
    "            padding = 1,\n",
    "            bias = False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.layers_2n = self.get_layers(block, 16, 16, stride = 1)\n",
    "        self.layers_4n = self.get_layers(block, 16, 32, stride = 2)\n",
    "        self.layers_6n = self.get_layers(block, 32, 64, stride = 2)\n",
    "\n",
    "        self.avg_pool = nn.AvgPool2d(7, stride = 1)\n",
    "        self.fc_out = nn.Linear(64, num_classes)\n",
    "\n",
    "        for m in self.modules() : \n",
    "            if isinstance(m, nn.Conv2d) : \n",
    "                nn.init.kaiming_normal_(m.weight, mode = 'fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d) : \n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "    def get_layers(self, block, in_channels, out_channels, stride) : \n",
    "        if stride == 2 :\n",
    "            down_sample = True\n",
    "        else : \n",
    "            down_sample = False\n",
    "        \n",
    "        layer_list = nn.ModuleList([block(in_channels, out_channels, stride, down_sample)])\n",
    "\n",
    "        for _ in range(self.num_layers -1) :\n",
    "            layer_list.append(block(out_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layer_list)\n",
    "    \n",
    "    def forward(self,x) :\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layers_2n(x)\n",
    "        x = self.layers_4n(x)\n",
    "        x = self.layers_6n(x)\n",
    "        \n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_out(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet18() : \n",
    "    block = ResidualBlock\n",
    "    model = ResNet(3, block)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, optimizer, step_lr_scheduler, criterion, num_epoch, early_stop, model_path) : \n",
    "    import time\n",
    "\n",
    "    start_time = time.time()\n",
    "    early_stop_epoch = 0\n",
    "    best_val_loss = np.float('inf')\n",
    "\n",
    "    for epoch in range(num_epoch) : \n",
    "        for phase in ['train','valid'] : \n",
    "            if phase == 'train' : \n",
    "                model.train()\n",
    "                step_lr_scheduler.step()\n",
    "            elif phase == 'valid' : \n",
    "                model.eval()\n",
    "            \n",
    "            running_loss = 0\n",
    "            running_corr = 0\n",
    "            total = 0 \n",
    "\n",
    "\n",
    "            for x, y in dataloader[phase] : \n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                total += x.size(0)\n",
    "\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train') : \n",
    "                    output = model(x)\n",
    "                    loss = criterion(output, y)\n",
    "                    \n",
    "                    if phase == 'train' : \n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                running_corr += (output.argmax(1)==y).sum().item()\n",
    "            \n",
    "            epoch_loss = running_loss / total\n",
    "            epoch_acc = running_corr / total\n",
    "\n",
    "            if phase == 'valid' and epoch_loss < best_val_loss : \n",
    "                print(f'On Epoch {epoch}, Best Model Saved with Valid Loss {round(epoch_loss, 6)} and Acc {round(epoch_acc, 4)*100}%')\n",
    "                \n",
    "                best_val_loss = epoch_loss\n",
    "                best_acc = epoch_acc\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                early_stop_epoch = 0\n",
    "        \n",
    "            elif phase == 'valid' : \n",
    "                early_stop_epoch += 1\n",
    "\n",
    "        if early_stop_epoch >= early_stop : \n",
    "            \"Early Stop Occured on epoch\" + str(epoch)\n",
    "            break;\n",
    "    time_elapsed = time.time() - start_time\n",
    "    print(f'Training Complete in {time_elapsed//60}min {time_elapsed%60}sec')\n",
    "    print(f'Best Validation Loss : {round(best_val_loss, 6)} with Accuracy {round(best_acc,4)*100}%')\n",
    "\n",
    "\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Epoch 0, Best Model Saved with Valid Loss 0.001083 and Acc 77.91%\n",
      "On Epoch 1, Best Model Saved with Valid Loss 0.000668 and Acc 87.31%\n",
      "On Epoch 2, Best Model Saved with Valid Loss 0.000654 and Acc 87.72%\n",
      "On Epoch 3, Best Model Saved with Valid Loss 0.00058 and Acc 89.62%\n",
      "On Epoch 4, Best Model Saved with Valid Loss 0.000519 and Acc 90.7%\n",
      "On Epoch 8, Best Model Saved with Valid Loss 0.000486 and Acc 91.67%\n",
      "On Epoch 9, Best Model Saved with Valid Loss 0.000363 and Acc 93.61%\n",
      "Training Complete in 15.0min 41.32019376754761sec\n",
      "Best Validation Loss : 0.000363 with Accuracy 93.61%\n"
     ]
    }
   ],
   "source": [
    "resnet = resnet18().to(device)\n",
    "dataloader = return_dataloader(train_idx, valid_idx)\n",
    "optimizer = optim.Adam(resnet.parameters(), lr = 0.005)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "decay_epoch = [10*x for x in range(1,11)]\n",
    "step_lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
    "trained_resnet = train_model(resnet, dataloader, optimizer, step_lr_scheduler, loss_fn, num_epoch = 100, early_stop = 5, model_path =  'resent.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloder = DataLoader(dataset = fmnist_test, batch_size  = batch_size , shuffle = False)\n",
    "class_correct = [0 for x in fmnist_test.classes]\n",
    "total_correct = [0 for x in fmnist_test.classes]\n",
    "with torch.no_grad() : \n",
    "    for images, labels in test_dataloder : \n",
    "        images = images.to(device)\n",
    "        prediction_soft = trained_resnet(images)\n",
    "        prediction_hard = prediction_soft.argmax(1)\n",
    "\n",
    "        correction = (prediction_hard.cpu() == labels).squeeze()\n",
    "\n",
    "        for label,corr in zip(labels, correction) : \n",
    "            total_correct[label] += 1\n",
    "            if corr : \n",
    "                class_correct[label] += 1\n",
    "acc_per_class = [cl/to for cl, to in zip(class_correct, total_correct)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 옷 종류에 대해서 혼동하는 양상을 보임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of T-shirt/top : 86.1%\n",
      "Accuracy of Trouser : 98.2%\n",
      "Accuracy of Pullover : 91.5%\n",
      "Accuracy of Dress : 92.0%\n",
      "Accuracy of Coat : 91.3%\n",
      "Accuracy of Sandal : 98.0%\n",
      "Accuracy of Shirt : 80.3%\n",
      "Accuracy of Sneaker : 98.1%\n",
      "Accuracy of Bag : 99.1%\n",
      "Accuracy of Ankle boot : 96.6%\n",
      "\n",
      "Total Accuracy : 0.9312%\n"
     ]
    }
   ],
   "source": [
    "for cls, acc in zip(fmnist_test.classes, acc_per_class) : \n",
    "    print(f'Accuracy of {cls} : {round(acc*100,2)}%')\n",
    "print('')\n",
    "print(f'Total Accuracy : {round(sum(class_correct) / sum(total_correct), 4)}%')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
